{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulYM8itj83Gn"
      },
      "source": [
        "# Data Download , Unzip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5QhFjgyi72G",
        "outputId": "306baa47-8eda-4b97-a5f8-c480c5ba6b12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zjbk8GXWOdna"
      },
      "outputs": [],
      "source": [
        "# COCO Dataset wget images ( train/val/test )\n",
        "!wget http://images.cocodataset.org/zips/train2017.zip\n",
        "!wget http://images.cocodataset.org/zips/val2017.zip\n",
        "!wget http://images.cocodataset.org/zips/test2017.zip\n",
        "\n",
        "# COCO Dataset wget annotations ( train/val/test )\n",
        "!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
        "!wget http://images.cocodataset.org/annotations/image_info_test2017.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_R0GeAV7EROP"
      },
      "outputs": [],
      "source": [
        "!mkdir /content/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2i5RujnoQizu",
        "outputId": "bf4c173b-735e-42a6-dfbe-48e2117b5826"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open /content/annotations_trainval2017.zip, /content/annotations_trainval2017.zip.zip or /content/annotations_trainval2017.zip.ZIP.\n",
            "unzip:  cannot find or open /content/test2017.zip, /content/test2017.zip.zip or /content/test2017.zip.ZIP.\n",
            "unzip:  cannot find or open /content/train2017.zip, /content/train2017.zip.zip or /content/train2017.zip.ZIP.\n",
            "unzip:  cannot find or open /content/val2017.zip, /content/val2017.zip.zip or /content/val2017.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "!unzip /content/annotations_trainval2017.zip -d /content/data\n",
        "\n",
        "!unzip /content/test2017.zip -d /content/data\n",
        "!unzip /content/train2017.zip -d /content/data\n",
        "!unzip /content/val2017.zip -d /content/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNo3LqSY8-kq"
      },
      "source": [
        "# Detectron2 Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsCj295raRo1",
        "outputId": "01effc81-4436-4716-96f2-f8f47378910e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'detectron2'...\n",
            "remote: Enumerating objects: 14474, done.\u001b[K\n",
            "remote: Counting objects: 100% (49/49), done.\u001b[K\n",
            "remote: Compressing objects: 100% (35/35), done.\u001b[K\n",
            "remote: Total 14474 (delta 18), reused 32 (delta 13), pack-reused 14425\u001b[K\n",
            "Receiving objects: 100% (14474/14474), 5.93 MiB | 18.06 MiB/s, done.\n",
            "Resolving deltas: 100% (10463/10463), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/facebookresearch/detectron2.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZtp-qjYqpos",
        "outputId": "0c4f69c5-7497-4543-e8fc-583a59f7385a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |█████████████▌                  | 834.1 MB 1.4 MB/s eta 0:13:47tcmalloc: large alloc 1147494400 bytes == 0x39656000 @  0x7efe4b0f9615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |█████████████████               | 1055.7 MB 1.3 MB/s eta 0:11:59tcmalloc: large alloc 1434370048 bytes == 0x7dcac000 @  0x7efe4b0f9615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |█████████████████████▋          | 1336.2 MB 1.3 MB/s eta 0:08:03tcmalloc: large alloc 1792966656 bytes == 0x2ade000 @  0x7efe4b0f9615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |███████████████████████████▎    | 1691.1 MB 1.2 MB/s eta 0:04:00tcmalloc: large alloc 2241208320 bytes == 0x6d8c6000 @  0x7efe4b0f9615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |████████████████████████████████| 1982.2 MB 1.2 MB/s eta 0:00:01tcmalloc: large alloc 1982251008 bytes == 0xf3228000 @  0x7efe4b0f81e7 0x4a3940 0x4a39cc 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9\n",
            "tcmalloc: large alloc 2477817856 bytes == 0x169494000 @  0x7efe4b0f9615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576\n",
            "\u001b[K     |████████████████████████████████| 1982.2 MB 5.2 kB/s \n",
            "\u001b[K     |████████████████████████████████| 17.6 MB 28 kB/s \n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 31.8 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.13.0 requires torch==1.12.0, but you have torch 1.8.0+cu111 which is incompatible.\u001b[0m\n",
            "\u001b[?25hLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (0.29.30)\n",
            "Collecting pyyaml==5.1\n",
            "  Downloading PyYAML-5.1.tar.gz (274 kB)\n",
            "\u001b[K     |████████████████████████████████| 274 kB 32.7 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyyaml\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.1-cp37-cp37m-linux_x86_64.whl size=44092 sha256=cd8e06d4b1a48bdf0751df6111d7bda6184ca833cd1fbe77d7482260247d7210\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/f5/10/d00a2bd30928b972790053b5de0c703ca87324f3fead0f2fd9\n",
            "Successfully built pyyaml\n",
            "Installing collected packages: pyyaml\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed pyyaml-5.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
            "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-skllwvyu\n",
            "  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-skllwvyu\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (57.4.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (0.29.30)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools==2.0) (3.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.1.0->pycocotools==2.0) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools==2.0) (1.15.0)\n",
            "Building wheels for collected packages: pycocotools\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0-cp37-cp37m-linux_x86_64.whl size=265174 sha256=362a797e1fec920db89efe0d20c444d32fcd414d0dade268b29602cdb197151b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7eesmoxt/wheels/e2/6b/1d/344ac773c7495ea0b85eb228bc66daec7400a143a92d36b7b1\n",
            "Successfully built pycocotools\n",
            "Installing collected packages: pycocotools\n",
            "  Attempting uninstall: pycocotools\n",
            "    Found existing installation: pycocotools 2.0.4\n",
            "    Uninstalling pycocotools-2.0.4:\n",
            "      Successfully uninstalled pycocotools-2.0.4\n",
            "Successfully installed pycocotools-2.0\n",
            "1.8.0+cu111 True\n",
            "gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Copyright (C) 2017 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# install dependencies: (use cu101 because colab has CUDA 10.1)\n",
        "#!pip install -U torch==1.8 torchvision==0.6 -f https://download.pytorch.org/whl/cu101/torch_stable.html\n",
        "!pip install -U torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html --quiet\n",
        "!pip install cython pyyaml==5.1\n",
        "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "!gcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hUSFYtR7qr_7",
        "outputId": "1ae7ae31-6088-4d2e-8ad6-abdb9712cbd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.8/index.html\n",
            "Collecting detectron2==0.6\n",
            "  Downloading https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.8/detectron2-0.6%2Bcu111-cp37-cp37m-linux_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 56.1 MB/s \n",
            "\u001b[?25hCollecting hydra-core>=1.1\n",
            "  Downloading hydra_core-1.2.0-py3-none-any.whl (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 29.7 MB/s \n",
            "\u001b[?25hCollecting iopath<0.1.10,>=0.1.7\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (3.2.2)\n",
            "Collecting black==21.4b2\n",
            "  Downloading black-21.4b2-py3-none-any.whl (130 kB)\n",
            "\u001b[K     |████████████████████████████████| 130 kB 58.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (4.64.0)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (1.3.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (1.3.0)\n",
            "Collecting yacs>=0.1.8\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (0.8.10)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (1.1.0)\n",
            "Collecting pycocotools>=2.0.2\n",
            "  Downloading pycocotools-2.0.4.tar.gz (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 25.3 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (0.16.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (2.8.0)\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (7.1.2)\n",
            "Collecting fvcore<0.1.6,>=0.1.5\n",
            "  Downloading fvcore-0.1.5.post20220512.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 4.8 MB/s \n",
            "\u001b[?25hCollecting omegaconf>=2.1\n",
            "  Downloading omegaconf-2.2.2-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.1 MB/s \n",
            "\u001b[?25hCollecting toml>=0.10.1\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: regex>=2020.1.8 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2==0.6) (2022.6.2)\n",
            "Collecting mypy-extensions>=0.4.3\n",
            "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2==0.6) (1.4.4)\n",
            "Collecting pathspec<1,>=0.8.1\n",
            "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2==0.6) (4.1.1)\n",
            "Collecting typed-ast>=1.4.2\n",
            "  Downloading typed_ast-1.5.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (843 kB)\n",
            "\u001b[K     |████████████████████████████████| 843 kB 58.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2==0.6) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (5.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.1->detectron2==0.6) (5.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.1->detectron2==0.6) (21.3)\n",
            "Collecting antlr4-python3-runtime==4.9.*\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[K     |████████████████████████████████| 117 kB 73.6 MB/s \n",
            "\u001b[?25hCollecting portalocker\n",
            "  Downloading portalocker-2.5.1-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.6) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.6) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.6) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->detectron2==0.6) (1.15.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core>=1.1->detectron2==0.6) (3.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.2.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.8.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.47.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (3.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (0.6.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (0.37.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (3.4.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.6) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->detectron2==0.6) (4.12.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.6) (3.2.0)\n",
            "Building wheels for collected packages: fvcore, antlr4-python3-runtime, pycocotools\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20220512-py3-none-any.whl size=61288 sha256=5dc9b6cb20b5017b7d128a59d88c13e9797ed8a82a3fb6ec7d30a99f69ddf66f\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/20/f9/a11a0dd63f4c13678b2a5ec488e48078756505c7777b75b29e\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144575 sha256=0103be0d5e08efe3a7ea5bb8dfaef5ac4f0f8f7bf42bb0f2b5fc2d7b7b23d6c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/8d/53/2af8772d9aec614e3fc65e53d4a993ad73c61daa8bbd85a873\n",
            "  Building wheel for pycocotools (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0.4-cp37-cp37m-linux_x86_64.whl size=265252 sha256=5fef73487e7fd41ccd5a364eb86f17307cc887e3cdb9a87b131ae0610b4e77b8\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/5f/fa/f011e578cc76e1fc5be8dce30b3eb9fd00f337e744b3bba59b\n",
            "Successfully built fvcore antlr4-python3-runtime pycocotools\n",
            "Installing collected packages: portalocker, antlr4-python3-runtime, yacs, typed-ast, toml, pathspec, omegaconf, mypy-extensions, iopath, pycocotools, hydra-core, fvcore, black, detectron2\n",
            "  Attempting uninstall: pycocotools\n",
            "    Found existing installation: pycocotools 2.0\n",
            "    Uninstalling pycocotools-2.0:\n",
            "      Successfully uninstalled pycocotools-2.0\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 black-21.4b2 detectron2-0.6+cu111 fvcore-0.1.5.post20220512 hydra-core-1.2.0 iopath-0.1.9 mypy-extensions-0.4.3 omegaconf-2.2.2 pathspec-0.9.0 portalocker-2.5.1 pycocotools-2.0.4 toml-0.10.2 typed-ast-1.5.4 yacs-0.1.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# install detectron2:\n",
        "!pip install detectron2==0.6 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.8/index.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKtcFPtIv5h5"
      },
      "source": [
        "# Detectron2 Model, Dataset Setting\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OANraaB-qiqQ"
      },
      "outputs": [],
      "source": [
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog\n",
        "from detectron2.data.catalog import DatasetCatalog\n",
        "from detectron2.config import get_cfg\n",
        "import random\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpUMP8E9pc3u"
      },
      "outputs": [],
      "source": [
        "# json 및 Image path setting\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "\n",
        "register_coco_instances(\"my_dataset_train\", {}, \"/content/data/annotations/instances_train2017.json\", \"/content/data/train2017\")\n",
        "register_coco_instances(\"my_dataset_val\", {}, \"/content/data/annotations/instances_val2017.json\", \"/content/data/val2017\")\n",
        "# register_coco_instances(\"my_dataset_test\", {}, \"/content/test/_annotations.coco.json\", \"/content/test\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k67b9xOTrxdW"
      },
      "outputs": [],
      "source": [
        "#We are importing our own Trainer Module here to use the COCO validation evaluation during training. Otherwise no validation eval occurs.\n",
        "\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.evaluation import COCOEvaluator\n",
        "\n",
        "class CocoTrainer(DefaultTrainer):\n",
        "\n",
        "  @classmethod\n",
        "  def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
        "\n",
        "    if output_folder is None:\n",
        "        os.makedirs(\"coco_eval\", exist_ok=True)\n",
        "        output_folder = \"coco_eval\"\n",
        "\n",
        "    return COCOEvaluator(dataset_name, cfg, False, output_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hHSxjhaWd4K"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiFez8MYrxao"
      },
      "outputs": [],
      "source": [
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
        "cfg.DATASETS.TEST = (\"my_dataset_val\",)\n",
        "\n",
        "cfg.DATALOADER.NUM_WORKERS = 4\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
        "cfg.SOLVER.IMS_PER_BATCH = 4\n",
        "cfg.SOLVER.BASE_LR = 0.001\n",
        "\n",
        "\n",
        "cfg.SOLVER.WARMUP_ITERS = 500\n",
        "cfg.SOLVER.MAX_ITER = 1000 #adjust up if val mAP is still rising, adjust down if overfit\n",
        "cfg.SOLVER.STEPS = (1000, 1500)\n",
        "cfg.SOLVER.GAMMA = 0.05\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 80 \n",
        "cfg.TEST.EVAL_PERIOD = 500\n",
        "\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = CocoTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o18y5_tfrP4K"
      },
      "source": [
        "# Inference Run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwJyIhFzxJe_"
      },
      "source": [
        "## Inpating setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kfzJgrvxMMf"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "# 깃허브 repository 가져오기\n",
        "!git clone https://github.com/saic-mdal/lama.git\n",
        "\n",
        "# 라이브러리 설치\n",
        "!pip install -r lama/requirements.txt --quiet\n",
        "!pip install wget --quiet\n",
        "!pip install torchtext==0.9\n",
        "\n",
        "# 경로이동\n",
        "%cd /content/lama\n",
        "\n",
        "# weight 다운로드\n",
        "!curl -L $(yadisk-direct https://disk.yandex.ru/d/ouP6l8VJ0HpMZg) -o big-lama.zip\n",
        "!unzip big-lama.zip\n",
        "\n",
        "# 라이브러리 설치\n",
        "!pip uninstall opencv-python-headless -y --quiet\n",
        "!pip install opencv-python-headless==4.1.2.30 --quiet\n",
        "\n",
        "# 라이브러리 호출\n",
        "import base64, os\n",
        "from IPython.display import HTML, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import wget\n",
        "from shutil import copyfile\n",
        "import shutil\n",
        "\n",
        "\n",
        "\n",
        "canvas_html = \"\"\"\n",
        "<style>\n",
        ".button {\n",
        "  background-color: #4CAF50;\n",
        "  border: none;\n",
        "  color: white;\n",
        "  padding: 15px 32px;\n",
        "  text-align: center;\n",
        "  text-decoration: none;\n",
        "  display: inline-block;\n",
        "  font-size: 16px;\n",
        "  margin: 4px 2px;\n",
        "  cursor: pointer;\n",
        "}\n",
        "</style>\n",
        "<canvas1 width=%d height=%d>\n",
        "</canvas1>\n",
        "<canvas width=%d height=%d>\n",
        "</canvas>\n",
        "\n",
        "<button class=\"button\">Finish</button>\n",
        "<script>\n",
        "var canvas = document.querySelector('canvas')\n",
        "var ctx = canvas.getContext('2d')\n",
        "\n",
        "var canvas1 = document.querySelector('canvas1')\n",
        "var ctx1 = canvas.getContext('2d')\n",
        "\n",
        "\n",
        "ctx.strokeStyle = 'red';\n",
        "\n",
        "var img = new Image();\n",
        "img.src = \"data:image/%s;charset=utf-8;base64,%s\";\n",
        "console.log(img)\n",
        "img.onload = function() {\n",
        "  ctx1.drawImage(img, 0, 0);\n",
        "};\n",
        "img.crossOrigin = 'Anonymous';\n",
        "\n",
        "ctx.clearRect(0, 0, canvas.width, canvas.height);\n",
        "\n",
        "ctx.lineWidth = %d\n",
        "var button = document.querySelector('button')\n",
        "var mouse = {x: 0, y: 0}\n",
        "\n",
        "canvas.addEventListener('mousemove', function(e) {\n",
        "  mouse.x = e.pageX - this.offsetLeft\n",
        "  mouse.y = e.pageY - this.offsetTop\n",
        "})\n",
        "canvas.onmousedown = ()=>{\n",
        "  ctx.beginPath()\n",
        "  ctx.moveTo(mouse.x, mouse.y)\n",
        "  canvas.addEventListener('mousemove', onPaint)\n",
        "}\n",
        "canvas.onmouseup = ()=>{\n",
        "  canvas.removeEventListener('mousemove', onPaint)\n",
        "}\n",
        "var onPaint = ()=>{\n",
        "  ctx.lineTo(mouse.x, mouse.y)\n",
        "  ctx.stroke()\n",
        "}\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "  button.onclick = ()=>{\n",
        "    resolve(canvas.toDataURL('image/png'))\n",
        "  }\n",
        "})\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "# 그림 그리는 함수 선언\n",
        "def draw(imgm, filename='drawing.png', w=400, h=200, line_width=1):\n",
        "  display(HTML(canvas_html % (w, h, w,h, filename.split('.')[-1], imgm, line_width)))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lm55SCSrS97"
      },
      "source": [
        "## pretrain weight down (detectron2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgdnSJLADAZi",
        "outputId": "6b7edfe2-e176-4e31-c895-6c1247424461"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "--2022-07-29 06:08:42--  https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x/139653917/model_final_2d9806.pkl\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 104.22.74.142, 172.67.9.4, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 431414189 (411M) [application/octet-stream]\n",
            "Saving to: ‘model_final_2d9806.pkl’\n",
            "\n",
            "model_final_2d9806. 100%[===================>] 411.43M  17.0MB/s    in 25s     \n",
            "\n",
            "2022-07-29 06:09:08 (16.2 MB/s) - ‘model_final_2d9806.pkl’ saved [431414189/431414189]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# https://github.com/facebookresearch/detectron2/blob/main/MODEL_ZOO.md\n",
        "%cd /content\n",
        "!wget https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x/139653917/model_final_2d9806.pkl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gqWqtB-rcyq"
      },
      "source": [
        "## cropper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_z-hmtQL3g9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from matplotlib.image import imread\n",
        "\n",
        "def cropper(org_image_path, mask_array, out_file_name):\n",
        "    num_instances = mask_array.shape[0]\n",
        "    mask_array = np.moveaxis(mask_array, 0, -1)\n",
        "    mask_array_instance = []\n",
        "    img = imread(str(org_image_path))\n",
        "    output = np.zeros_like(img)\n",
        "    for i in range(num_instances):\n",
        "        # a = mask_array[:, :, i:(i+1)]\n",
        "        mask_array_instance.append(mask_array[:, :, i:(i+1)])\n",
        "        output = np.where(mask_array_instance[i] == True, 255, output)\n",
        "\n",
        "    im = Image.fromarray(output)\n",
        "    im.save(out_file_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eo9z4eYirV2G"
      },
      "source": [
        "## Inference cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2xWOeyj7Bgv"
      },
      "outputs": [],
      "source": [
        "!mkdir /content/data/test2017\n",
        "!mkdir /content/data/output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGKiZ-Y7kvlL"
      },
      "outputs": [],
      "source": [
        "# image /content/data/test2017/file 넣기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-eQ1Ksb2B2r"
      },
      "outputs": [],
      "source": [
        "cfg = get_cfg()\n",
        "cfg.OUTPUT_DIR = '/content/data/output/'\n",
        "\n",
        "cfg.merge_from_file(\"/content/detectron2/configs/COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\")\n",
        "cfg.MODEL.WEIGHTS = \"/content/model_final_2d9806.pkl\"\n",
        "\n",
        "cfg.DATASETS.TEST = (\"my_dataset_test\", )\n",
        "\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.4   # set the testing threshold for this model\n",
        "predictor = DefaultPredictor(cfg)\n",
        "test_metadata = MetadataCatalog.get(\"my_dataset_test\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsoijV_1xM0O"
      },
      "source": [
        "# Detector Segmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## coco dic"
      ],
      "metadata": {
        "id": "KsZwqoTOmTAb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2OhDhD2Dzgy",
        "outputId": "e2627ddc-cd09-4400-98a9-a9a63e221e98"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "coco_class = {\n",
        " '0': 'person',\n",
        " '1': 'bicycle',\n",
        " '10': 'fire hydrant',\n",
        " '11': 'stop sign',\n",
        " '12': 'parking meter',\n",
        " '13': 'bench',\n",
        " '14': 'bird',\n",
        " '15': 'cat',\n",
        " '16': 'dog',\n",
        " '17': 'horse',\n",
        " '18': 'sheep',\n",
        " '19': 'cow',\n",
        " '2': 'car',\n",
        " '20': 'elephant',\n",
        " '21': 'bear',\n",
        " '22': 'zebra',\n",
        " '23': 'giraffe',\n",
        " '24': 'backpack',\n",
        " '25': 'umbrella',\n",
        " '26': 'handbag',\n",
        " '27': 'tie',\n",
        " '28': 'suitcase',\n",
        " '29': 'frisbee',\n",
        " '3': 'motorbike',\n",
        " '30': 'skis',\n",
        " '31': 'snowboard',\n",
        " '32': 'sports ball',\n",
        " '33': 'kite',\n",
        " '34': 'baseball bat',\n",
        " '35': 'baseball glove',\n",
        " '36': 'skateboard',\n",
        " '37': 'surfboard',\n",
        " '38': 'tennis racket',\n",
        " '39': 'bottle',\n",
        " '4': 'aeroplane',\n",
        " '40': 'wine glass',\n",
        " '41': 'cup',\n",
        " '42': 'fork',\n",
        " '43': 'knife',\n",
        " '44': 'spoon',\n",
        " '45': 'bowl',\n",
        " '46': 'banana',\n",
        " '47': 'apple',\n",
        " '48': 'sandwich',\n",
        " '49': 'orange',\n",
        " '5': 'bus',\n",
        " '50': 'broccoli',\n",
        " '51': 'carrot',\n",
        " '52': 'hot dog',\n",
        " '53': 'pizza',\n",
        " '54': 'donut',\n",
        " '55': 'cake',\n",
        " '56': 'chair',\n",
        " '57': 'sofa',\n",
        " '58': 'pottedplant',\n",
        " '59': 'bed',\n",
        " '6': 'train',\n",
        " '60': 'diningtable',\n",
        " '61': 'toilet',\n",
        " '62': 'tvmonitor',\n",
        " '63': 'laptop',\n",
        " '64': 'mouse',\n",
        " '65': 'remote',\n",
        " '66': 'keyboard',\n",
        " '67': 'cell phone',\n",
        " '68': 'microwave',\n",
        " '69': 'oven',\n",
        " '7': 'truck',\n",
        " '70': 'toaster',\n",
        " '71': 'sink',\n",
        " '72': 'refrigerator',\n",
        " '73': 'book',\n",
        " '74': 'clock',\n",
        " '75': 'vase',\n",
        " '76': 'scissors',\n",
        " '77': 'teddy bear',\n",
        " '78': 'hair drier',\n",
        " '79': 'toothbrush',\n",
        " '8': 'boat',\n",
        " '9': 'traffic light'\n",
        "\n",
        "}\n",
        "len(coco_class.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUYkY7n6zh6j"
      },
      "outputs": [],
      "source": [
        "!mkdir /content/lama/data_for_prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## inspector inspector_class"
      ],
      "metadata": {
        "id": "5raBP9gZmYtb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iinKuT6sKE7U"
      },
      "outputs": [],
      "source": [
        "def inspector(select):\n",
        "    \n",
        "    while 1 : \n",
        "        if len(select) == 0 :\n",
        "            select = input('공백 또는 입력하신 값이 없습니다. 다시 입력해주세요. : ')\n",
        "            continue\n",
        "\n",
        "\n",
        "        b = re.sub('[0-9\\s]', '', select)\n",
        "        if len(b) != 0 :\n",
        "        \n",
        "            select = input('숫자 공백을 제외한 문자와 같이 입력되었습니다. 다시 입력 해주세요 : ')\n",
        "\n",
        "        elif len(b) == 0 :\n",
        "            select = list(map(int, select.split()))\n",
        "\n",
        "            if len(boxes)-1 >= max(select) :\n",
        "                break\n",
        "\n",
        "            select = input('입력하신 번호는 선택하실 수 있는 번호 내에 없습니다. 다시 입력 해주세요 : ')\n",
        "\n",
        "    return select\n",
        "\n",
        "def inspector_class(select):\n",
        "    \n",
        "    while 1 : \n",
        "        if len(select) == 0 :\n",
        "            select = input('공백 또는 입력하신 값이 없습니다. 다시 입력해주세요. : ')\n",
        "            continue\n",
        "\n",
        "\n",
        "        b = re.sub('[0-9\\s]', '', select)\n",
        "        if len(b) != 0 :\n",
        "        \n",
        "            select = input('숫자 공백을 제외한 문자와 같이 입력되었습니다. 다시 입력 해주세요 : ')\n",
        "\n",
        "        elif len(b) == 0 :\n",
        "            select = list(map(int, select.split()))\n",
        "            cnt = 0\n",
        "            for aa in select :\n",
        "                if aa in class_cate :\n",
        "                    continue\n",
        "                cnt += 1\n",
        "\n",
        "            if cnt != 0 :\n",
        "                print('')\n",
        "                print('번호를 찾을 수 없습니다. 번호를 확인하시고 띄어쓰기를 기준으로 입력해주세요.')\n",
        "                select = input('선택하시는 종류의 번호를 다시 선택해주세요 : ')\n",
        "            \n",
        "            else : break\n",
        "                    \n",
        "    return select\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nq6cEoxhDZ1t"
      },
      "outputs": [],
      "source": [
        "# !rm -rf /content/data\n",
        "\n",
        "# !mkdir -p /content/data/output\n",
        "# !mkdir -p /content/data/test2017"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/장기프로젝트/koreandataset/videoplayback.zip -d /content"
      ],
      "metadata": {
        "id": "v-_v7-yZOgeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for a in os.listdir('/content/content/videoplayback') :\n",
        "    shutil.move('/content/content/videoplayback/'+a, '/content/data/test2017')\n",
        "\n",
        "!rm -rf /content/content"
      ],
      "metadata": {
        "id": "VZ6HudB_Oivd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QTB_xCmwCt7",
        "outputId": "c7fe0b61-22f1-4a40-b74a-45b5c2a1a608"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [06:24<00:00,  1.04it/s]\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "##########################\n",
        "coco_dic = coco_class\n",
        "##########################\n",
        "\n",
        "img_list = sorted(os.listdir('/content/data/test2017/'))[:400]\n",
        "\n",
        "for imageName in tqdm(img_list):\n",
        "    im = cv2.imread('/content/data/test2017/' + imageName)\n",
        "    \n",
        "    h, w, _ = im.shape\n",
        "\n",
        "    outputs = predictor(im)\n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                metadata=test_metadata, \n",
        "                scale=1,\n",
        "                # instance_mode=ColorMode.IMAGE_BW # 굳이 필욘 없네 # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
        "                    )\n",
        "\n",
        "    idxofClass = [i for i, x in enumerate(list(outputs['instances'].pred_classes))] #if x == 0]\n",
        "\n",
        "    o = outputs[\"instances\"]\n",
        "    \n",
        "    boxes = o.pred_boxes[idxofClass]\n",
        "    masks = o.pred_masks[idxofClass]\n",
        "\n",
        "    obj = detectron2.structures.instances.Instances(image_size=()) #w,h인지 h,w인지 모름\n",
        "\n",
        "\n",
        "    obj.set('pred_boxes', boxes)\n",
        "    obj.set('pred_masks', masks)\n",
        "\n",
        "\n",
        "    out = v.draw_instance_predictions(obj.to(\"cpu\"))\n",
        "\n",
        "    boxes = v._convert_boxes(outputs[\"instances\"].pred_boxes.to('cpu'))#.squeeze()\n",
        "\n",
        "    for idx, box in enumerate(boxes):\n",
        "        pred_class_num = outputs['instances'][idx].pred_classes.tolist()[0]\n",
        "        class_text = coco_dic[str(pred_class_num)]\n",
        "        \n",
        "        out = v.draw_text(f\"{idx} : {class_text}\", ((box[0]+box[2])/2, (box[1]+box[3])/2), font_size = h//45, color = 'g') # 0번부터 아니고 1번부터 시작으로 할 수 있을 듯 (사용자 편의)\n",
        "\n",
        "    # cv2_imshow(out.get_image()[:, :, ::-1])\n",
        "\n",
        "    # # 사진이 print되는데 시간이 걸려서 대기시간 줌\n",
        "    # time.sleep(3)\n",
        "\n",
        "#############\n",
        "    mask = outputs['instances'].pred_masks\n",
        "\n",
        "    class_cate = outputs['instances'].to('cpu').pred_classes.tolist()\n",
        "    class_cate = list(set(class_cate))\n",
        "\n",
        "    # print('------선택지-------')\n",
        "    # for c in class_cate :\n",
        "        # print(f'{c} : {coco_dic[str(c)]}')\n",
        "    \n",
        "    # print('-------------------')\n",
        "    # print('')\n",
        "\n",
        "    # select = input('')\n",
        "\n",
        "    # select = inspector_class(select)\n",
        "\n",
        "    # print('')\n",
        "    # if len(select) == 0 :\n",
        "        # print('수정할 물체가 없습니다.')\n",
        "        # continue\n",
        "    # print('')\n",
        "\n",
        "\n",
        "\n",
        "    tensor_list = []\n",
        "    aaaa = [2, 4, 5, 7, 8]\n",
        "    for idx in range(len(outputs['instances'])) :\n",
        "        # if outputs['instances'][idx].pred_classes.tolist()[0] in aaaa :\n",
        "        #     tensor_list.append(mask[idx])\n",
        "        tensor_list.append(mask[idx])\n",
        "\n",
        "    if len(tensor_list) >0 :\n",
        "        tensor_stack = torch.stack(tensor_list)\n",
        "    else :\n",
        "        print('바꿀내용이없습니다')\n",
        "        continue\n",
        "\n",
        "\n",
        "    img_root = '/content/data/test2017/'\n",
        "    img_path = img_root + imageName\n",
        "    out_root = '/content/data/output/'\n",
        "    out_path = out_root + imageName\n",
        "\n",
        "    mask_array = tensor_stack.cpu().numpy()\n",
        "\n",
        "    cropper(img_path, mask_array, out_path)\n",
        "\n",
        "    shutil.copy(img_path, '/content/lama/data_for_prediction/'+imageName.split('.')[0]+'.jpg')\n",
        "    # for dilate\n",
        "    mask = cv2.imread(out_path)\n",
        "    size = cv2.getStructuringElement(cv2.MORPH_RECT, (60, 60)) # (10, 10) 클 수록 팽창 범위 증가\n",
        "    dilate_img = cv2.dilate(mask, size)\n",
        "    \n",
        "    cv2.imwrite('/content/lama/data_for_prediction/'+imageName.split('.')[0] +'_mask.png', dilate_img)\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVLXBdmlyGNw"
      },
      "source": [
        "# Inpainting Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9Xy0x15vW7v",
        "outputId": "d72c0abc-0b41-4ab9-d4f0-4c8fad8bd649"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/lama\n"
          ]
        }
      ],
      "source": [
        "%cd /content/lama\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# plt.rcParams[\"figure.figsize\"] = (15,5)\n",
        "# plt.rcParams['figure.dpi'] = 200\n",
        "# plt.subplot(131)\n",
        "\n",
        "!PYTHONPATH=. TORCH_HOME=$(pwd) python3 bin/predict.py model.path=$(pwd)/big-lama indir=$(pwd)/data_for_prediction outdir=/content/output dataset.img_suffix=.jpg > /dev/null\n",
        "\n",
        "\n",
        "# for a in os.listdir('/content/output')[:-4] :\n",
        "#   # 출력데이터도 png\n",
        "#   plt.imshow(plt.imread(f\"/content/output/\"+a))\n",
        "#   _=plt.axis('off')\n",
        "#   _=plt.title('inpainting result')\n",
        "#   plt.show()\n",
        "#   fname = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1gO2_PzFJAY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b295971a-8ca1-47b8-f958-5117365cbf3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 794/794 [00:54<00:00, 14.67it/s]\n"
          ]
        }
      ],
      "source": [
        "# import cv2\n",
        "# import numpy as np\n",
        "# import glob\n",
        "\n",
        "# frameSize = (1920, 1080)\n",
        "\n",
        "# out = cv2.VideoWriter('/content/test.mp4',cv2.VideoWriter_fourcc(*'DIVX'), 29, frameSize)\n",
        "\n",
        "# for filename in tqdm(sorted(glob.glob('/content/output/*.png'))):\n",
        "#     img = cv2.imread(filename)\n",
        "#     out.write(img)\n",
        "\n",
        "# out.release()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# shutil.copy('/content/test.mp4', '/content/drive/MyDrive/공유폴더/inpatingvideo.mp4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WIb0d07AafnC",
        "outputId": "0c5fcf46-d90f-4d7f-aef8-f2ab0ee83058"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/공유폴더/inpatingvideo.mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "T8zaCD-aGStX"
      },
      "outputs": [],
      "source": [
        "# from IPython.display import HTML\n",
        "# from base64 import b64encode\n",
        " \n",
        "# def show_video(video_path, video_width = 600):\n",
        "   \n",
        "#   video_file = open(video_path, \"r+b\").read()\n",
        " \n",
        "#   video_url = f\"data:video/mp4;base64,{b64encode(video_file).decode()}\"\n",
        "#   return HTML(f\"\"\"<video width={video_width} controls><source src=\"{video_url}\"></video>\"\"\")\n",
        " \n",
        "# show_video('/content/test.mp4')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "영상 inpainting"
      ],
      "metadata": {
        "id": "cihhtyB1Kpfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/videoinpainting/jpg\n",
        "!mkdir -p /content/videoinpainting/mask"
      ],
      "metadata": {
        "id": "NjfO9zYRLIQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for aa in os.listdir('/content/lama/data_for_prediction') :\n",
        "    if aa[-3:] == 'jpg' :\n",
        "        shutil.copy('/content/lama/data_for_prediction/'+aa , '/content/videoinpainting/jpg')\n",
        "    if aa[-3:] == 'png' :\n",
        "        shutil.copy('/content/lama/data_for_prediction/'+aa, '/content/videoinpainting/mask/'+aa[:-9]+'.jpg')\n"
      ],
      "metadata": {
        "id": "V9Ob9kmhK9AV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil"
      ],
      "metadata": {
        "id": "BlQaCj8RMV0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/ruiliu-ai/FuseFormer.git\n",
        "\n",
        "%cd FuseFormer\n",
        "!pip install -r requirements.txt\n",
        "!mkdir /content/FuseFormer/checkpoints\n",
        "shutil.copy('/content/drive/MyDrive/장기프로젝트/koreandataset/fuseformer.pth', '/content/FuseFormer/checkpoints/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        },
        "id": "RCgoQtSyKr5-",
        "outputId": "583aa5a0-a2db-4452-bcb5-337899661660"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'FuseFormer'...\n",
            "remote: Enumerating objects: 62, done.\u001b[K\n",
            "remote: Counting objects: 100% (62/62), done.\u001b[K\n",
            "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
            "remote: Total 62 (delta 24), reused 50 (delta 12), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (62/62), done.\n",
            "/content/FuseFormer\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (4.6.0.66)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (4.64.0)\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 37.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.7.3)\n",
            "Collecting scikit-image==0.15.0\n",
            "  Downloading scikit_image-0.15.0-cp37-cp37m-manylinux1_x86_64.whl (26.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.3 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting pillow==7.2.0\n",
            "  Downloading Pillow-7.2.0-cp37-cp37m-manylinux1_x86_64.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 42.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.15.0->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: imageio>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.15.0->-r requirements.txt (line 5)) (2.4.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.15.0->-r requirements.txt (line 5)) (3.2.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.15.0->-r requirements.txt (line 5)) (2.6.3)\n",
            "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy->-r requirements.txt (line 4)) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.15.0->-r requirements.txt (line 5)) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.15.0->-r requirements.txt (line 5)) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.15.0->-r requirements.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.15.0->-r requirements.txt (line 5)) (1.4.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image==0.15.0->-r requirements.txt (line 5)) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image==0.15.0->-r requirements.txt (line 5)) (1.15.0)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX->-r requirements.txt (line 3)) (3.17.3)\n",
            "Installing collected packages: pillow, tensorboardX, scikit-image\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.17.2\n",
            "    Uninstalling scikit-image-0.17.2:\n",
            "      Successfully uninstalled scikit-image-0.17.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.5.2 requires scikit-image>=0.16.1, but you have scikit-image 0.15.0 which is incompatible.\u001b[0m\n",
            "Successfully installed pillow-7.2.0 scikit-image-0.15.0 tensorboardX-2.5.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/FuseFormer/checkpoints/fuseformer.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fp7E0D5zZKmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/FuseFormer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUIn11ECogQ_",
        "outputId": "9cc76695-73ea-472e-d4ec-7e1a1e8e4b62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/FuseFormer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test.py -c /content/FuseFormer/checkpoints/fuseformer.pth -v /content/videoinpainting/jpg -m /content/videoinpainting/mask --width 864 --height 480 --outw 864 --outh 480"
      ],
      "metadata": {
        "id": "k0jUc6k7MeFT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d69cee75-6958-4b69-bc98-94afc044de10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading from: /content/FuseFormer/checkpoints/fuseformer.pth\n",
            "loading videos and masks from: /content/videoinpainting/jpg\n",
            "0 6 3\n",
            "Traceback (most recent call last):\n",
            "  File \"test.py\", line 160, in <module>\n",
            "    main_worker()\n",
            "  File \"test.py\", line 135, in main_worker\n",
            "    pred_img = model(masked_imgs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/FuseFormer/model/fuseformer.py\", line 158, in forward\n",
            "    trans_feat = self.transformer(trans_feat)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\", line 119, in forward\n",
            "    input = module(input)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/FuseFormer/model/fuseformer.py\", line 343, in forward\n",
            "    x = input + self.dropout(self.attention(x))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/FuseFormer/model/fuseformer.py\", line 276, in forward\n",
            "    att, _ = self.attention(query, key, value)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/FuseFormer/model/fuseformer.py\", line 193, in forward\n",
            "    scores = torch.matmul(query, key.transpose(-2, -1)\n",
            "RuntimeError: CUDA out of memory. Tried to allocate 10.01 GiB (GPU 0; 14.76 GiB total capacity; 1.08 GiB already allocated; 9.30 GiB free; 1.42 GiB reserved in total by PyTorch)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for a in sorted(os.listdir('/content/videoinpainting/jpg'))[40:] : \n",
        "    os.remove('/content/videoinpainting/jpg/'+a)\n",
        "    \n",
        "for a in sorted(os.listdir('/content/videoinpainting/mask'))[40:] : \n",
        "    os.remove('/content/videoinpainting/mask/'+a)\n"
      ],
      "metadata": {
        "id": "oGwYXX2qMx0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HZHPKVgWnZpZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
